\documentclass[a4paper,12pt]{article}
\usepackage{graphicx}
\begin{document}
\title{Thoughts Related to Learning Programs}
\author{Irvin Hwang}
\maketitle

\section{Structure in Problem Solving}
What is structure?  In problem solving it is often said a particularly elegant solution takes advantage of the ``structure'' of a problem, but what does this mean?  A related question is what is it about problems that allows us to solve them efficiently (i.e. through techniques other than brute-force search)?  We look at the problem of sorting as a case-study.  In the sorting problem we are given a list of objects on which an unknown total order exists, but can be learned by comparing pairs of objects.  The goal is to gain enough information through comparisons to place the objects in an increasing order.  Perhaps the most naive way of solving this problem is to compare all possible pairs of objects and once the relationship is known between each pair of objects placing them in order is trivial.  One would have to make O($n^2$) comparisons, but we know there are more efficient algorithms for this problem.  

In quicksort one takes a ``pivot'' element and divides all the other elements into two groups, a set of elements smaller than the pivot and a set of elements greater than the pivot (we assume all elements are different for simplicity).  Each group is sorted (recursively) and then one concatenates the two lists together to get a completely sorted list.  What is it that makes this more efficient?  The main thing to note is that every element in the small group is smaller than every element in the large group due to transitivity.  This means we can save on the amount of computation we perform by not having to compare elements of the small group with elements in the big group.

In mergesort one splits a set of elements up into indivdual pieces then recursively merges these pieces pairwise into larger and larger ordered lists.   The merge works by always taking the smallest element between the head of the two lists as the next element of the merged list.  Again we can attribute the efficiency of this algorithm to transitivity since the smaller of the two heads will be smaller than all the items in the list with the larger head.  This means we do not have to compare every item to every other item in the lists.

The point here is that one might say these algorithms take advantage of the structure of the problem and that's why they're more efficient than a brute-force method.  And we see structure is really just a property (transitivity) that contrains the possible values of a relation (the total order) and this relation is what we use to solve the problem.  One could argue that most problems involve reasoning about relationships between objects and finding patterns or structure in these relationships is a fundamental aspect of problem solving.

If we examine the situation in terms of cognition we can imagine people experimenting with the problem and comparing items semi-randomly, but beginning to recognize a pattern that when they find $a<b$ and $b<c$ then it is always the case $a<c$.  This pattern or structure can then be represented as a rule or computation that takes two inputs $a<b$ and $b<c$ and produces an output $a<c$.  The question then is how do people recognize this structure or abstract out this rule/computation based on experience?

\section{Patterns and Computation}
  Human survival is dependent on the ability to model and reason about our environment.  If the data we received from our senses was completely random, if the world had no structure or pattern, we would be unable to deal with the complexity of our surroundings given our finite mental resources.  The fact that the world is not random combined with our ability to recognize and reason over patterns is what allows us to exist in this world.  

To get a more concrete sense of what we mean by pattern let us look at
a particular example (Figure \ref{fig:patterns}).  Suppose we have an image like the one below. 
\begin{figure}[htbp]
\begin{center}
%\includegraphics{fig275.pdf}
\includegraphics[scale=.5]{patterns.pdf}
\caption{This figure has a pattern of position and a pattern of size. }
\label{fig:patterns}
\end{center}
\end{figure}

This image does not seem randomly generated and most people would
quickly recognize the presence of two patterns 1) the positions of the objects fall on a line and 2) they decrease in
size.  One way to think about these patterns is that they constrain how the data behave.  For example if we were to add an object number five we would probably be able to restrict the possible values for both the position and size of the new object.  What does this mean more formally?  In the case of the first
pattern when we look at the centered position of the objects the
coordinates satisfy a linear relation represented by the computation
$y=mx+b$.  In the second case we see the relation $i<i+1$ holds where $i$ is
the area of the $i$th object.  In both cases we found that a computable
relation held for the data where data in the first pattern were object
positions and data in the second case were areas for the objects.  At
this point one might object to the use of symbols or "rules"
considering these patterns can be recognized without knowledge of the
formal equations.  The important thing to note is the relation that
defines the pattern exists independent of how it is represented and
computed.  Here we represented the relation by computations in a
formal system, but one can also imagine representing the same relation
as computations in a neural circuit etc.  From these examples we can
now intuitively define pattern recognition as finding computations summarizing a relation that constrains the data. 

A computation is essentially any sort of transformation.  There are many formal models of computation such as Turing
machines, the lambda calculus, etc. and there is a widely accepted
hypothesis, the Church-Turing thesis, that any computation (e.g. a computation made by a neural
network) can be expressed in terms of one of these formal models.  Perhaps the best way to think
about computations for our needs is in the language of algorithms and the most common way of representing algorithms is as expressions in some programming
language.  The main difficulty with pattern recognition i.e. finding computations to express relations in data is the space of expressions in a given programming language is huge.  We begin our explorations into pattern recognition by looking at a different, but related problem of how we learn algorithms.

\subsection{Program Induction and Reinforcment Learning}
\subsubsection{Overview}
An algorithm can be thought of as a sequence of actions for solving a problem.  One domain that deals with the process of learning an action sequence for solving a problem is reinforcement learning (RL).  A policy (the output of a reinforcment learning algorithm) can be viewed as a set of computations (action sequences)
that end with the solution to a problem.  An algorithm can be thought
of as a compact representation of the policy that captures the patterns within the set of action sequences.  For example if we revisit the problem of sorting objects one can think of the policy as a map from the known relations between objects and permutations of their order to actions such like comparison and reordering.  Given a particular permutation and no known relationships we can generate an action sequence by taking the action the policy maps to this particular state  and repeating the process with the new state until the goal is reached.   If one were to represent this map as a table it could be quite large depending on the size of the list, but an algorithm for sorting is of constant size and given any list tells the sequence of actions to take in order to reach the goal.

Classical RL algorithms provide a way to learn the mapping from states to actions, but do not scale well due to the exponential growth of the mapping as we increase the complexity of the problem (e.g. by adding features or actions).  These methods roughly work by attempting to estimate the value of an action in a particular state and the policy is defined as taking the actions with the highest value.  While there are methods for dealing with scalability via abstracting over the state space or approximating the value function, the resulting policy seems qualitatively different than what one typically thinks of as an algorithm.

We begin approaching the issue of learning algorithms by tweaking the setup of the problem based on our hypothesis that algorithms are compact representations of a policy that capture its patterns.  Suppose we already have part of the policy in the form of a set of successful action sequences (sequences of actions that go from an initial state to the goal state).  We would like to generalize from these action sequences an algorithm that would produce action sequences with a similar behavior when given a new input.  One possible direction for trying to do this is to look at how an algorithm produces a sequence of actions and then reverse that process.  

An algorithm is typically expressed in a programming language.  The programming language is defined by its syntax and semantics, where the syntax defines what makes an expression in the language and the semantics define how these expressions should be evaluated i.e. what actions to take.  We can roughly think of the semantics as a machine that takes in an expression in the language (an algorithm/program) and and produces a sequence of actions.  The semantics are made up of what are essentially a collection of if-then rules and so if we wish to infer an expression based on actions perhaps we can find the rules where our actions are the consequent (the ``then'' part of the rule) and make our expressions the antecedent (the ``if'' part of the rule).  The problem here is many expressions can evaluate to the same value and so the space of possible expressions would end up being quite large.  One possiblity is to use this approach to generate a sort of naive expression that is essentially a literal translation of the action sequences into an expression and then generalize from this expression into something compact using more sophisticated methods like in work of Ute Schmid \cite{Kitzelmann2006Inductive}. 

\subsection{Possible Approaches}
We propose to start by tackling a series of succesively complicated problems.  To demonstrate the approach we begin with the simple set-up of an RL problem with a single binary reward, a single binary action, a single binary feature, and we assume the Markov assumption holds in the sense the reward at a given time-step is only dependent on the feature of that time-step.  One should be able to express the algorithm for this problem as a single if expression conditioned upon the value of the single feature.

SPECIFY SYNTAX AND SEMANTICS OF THE LANGUAGE HERE

Two natural ways to guide progress are to either allow the language to become more complex by adding additional syntactic constructs and to find problems whose solutions would benefit from such constructs or to do the opposite and find more complex problems and then determine how the syntax might be changed to accodmodate this .   make the problem more difficult are to find problems that would benefit from more complex syntactic constructs (e.g. for loops/recursion) or to  

The language we use is defined by the following syntax and semantics
\begin{displaymath}
EXP := T\\
|F\\
|IF EXP EXP EXP
\end{displaymath}

Search starts at the features and the 

GO 
Neighborhood relation defined by the semantics (for MCMC)

THINK OF A GOOD WAY TO EXPRESS THE INTUITION OF AN ALGORITHM AS A SHORT POLICY

DUAL PROCESS MODEL AS A MODEL OF WHY SMALL EXAMPLES ARE USEFUL FOR GENERALIZATION.  FIRST STAGE ON GOOD EXAMPLES ALLOWS FOR GOOD GENERALIZATION

Let's look at the problem of sorting to get a concrete idea of the distinction between policy and algorithm.  Imagine a sorting task where we are presented with a set of objects on a line that have an unknown order (we do not know the order relation for any pair of objects) and we must put them in an increasing order.  The possible actions we can take are to compare two items and to change an item's position on the line.  The state space for the problem consists of the possible orders of the list along with the amount of knowledge about the order relation.  The most direct way to express a policy is as a table of states and actions which   
How
do we go from a policy (successful action sequences) to an algorithm?
We propose approaching this problem by using the formal semantics of
the language being used to represent computations/algorithms.  The
operational semantics of a programming language are a set of rules
that tell how and in what order expressions are evaluated.  We can
view state-action sequences going from initial states to goal states
as the result of evaluating an algorithm (expressions in the language)
according to its operational semantics where the initial states are
inputs to the algorithms i.e. an action sequence is end result of a
traversing through the operational semantics of the language using the
algorithm and the initial state.  Our goal then is to traverse the
semantics in the opposite direction by going from state-action
sequence to algorithm.  If one is familiar with how type inference
works, one can think of type inference as inference on the static
semantics of a programming language and what we are trying to do is
inference on the dynamic semantics.  The obvious hindrance is this
problem is not "well-defined" in the sense there are many possible
expressions that may evaluate to a particular action-sequence.  Our
hope is that using several successful action-sequences should
eliminate many candidate expressions and leave the ones that capture
what is common between the individual solutions.  What we have
established is a computational level description (in Marr's terms) of
the problem of abstraction, the computational problem is inference on
the operational semantics of a language.  What we need to do now is
develop efficient or approximate algorithms for this process.
Possible benefits of approaching the problem in this way include 1)
taking advantage of the structure of the problem as opposed to the
using more general search approaches like Bayesian inference 2)
possibly using the similiarity of dynamic semantics to statics
semantics to try and rework type inference algorithms for our
purposes.  A few of the many possible insights we may gain from this
approach are a more formal understanding of the relation between
language and cognition, a formal understanding of syntax and how new
syntactic constructions can arise, efficient policy representation in
RL, a better understanding of transfer in RL etc.





RL and Abstraction algorithms

\subsection{Learning algorithms and pattern recognition}

How do we find computations?  


Models are patterns.  Patterns are computations.  Computations are represented by algorithms.  How do we define algorithms? RL.
\subsection{}
\bibliography{myBib}
\end{document}
